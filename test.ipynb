{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc02c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu guy run this code and make sure weights are saved in /weights folder, then push to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f952861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "State dim: 4, Action dim: 2\n",
      "Epi 1/200 | Avg Steps (last 100): 13.00 | Steps: 13 | Time: 0.55s\n",
      "Reward: 13.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 2/200 | Avg Steps (last 100): 15.50 | Steps: 18 | Time: 0.61s\n",
      "Reward: 18.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 3/200 | Avg Steps (last 100): 13.67 | Steps: 10 | Time: 0.64s\n",
      "Reward: 10.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 0. 0. 0.]\n",
      "Epi 4/200 | Avg Steps (last 100): 14.25 | Steps: 16 | Time: 0.69s\n",
      "Reward: 16.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 5/200 | Avg Steps (last 100): 21.80 | Steps: 52 | Time: 0.85s\n",
      "Reward: 52.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 0. 1. 0.]\n",
      "Epi 6/200 | Avg Steps (last 100): 19.67 | Steps: 9 | Time: 0.88s\n",
      "Reward: 9.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 7/200 | Avg Steps (last 100): 19.71 | Steps: 20 | Time: 0.95s\n",
      "Reward: 20.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [0. 0. 0. 0.]\n",
      "Epi 8/200 | Avg Steps (last 100): 19.38 | Steps: 17 | Time: 1.00s\n",
      "Reward: 17.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 9/200 | Avg Steps (last 100): 18.67 | Steps: 13 | Time: 1.04s\n",
      "Reward: 13.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 10/200 | Avg Steps (last 100): 18.30 | Steps: 15 | Time: 1.10s\n",
      "Reward: 15.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 11/200 | Avg Steps (last 100): 17.64 | Steps: 11 | Time: 1.14s\n",
      "Reward: 11.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 12/200 | Avg Steps (last 100): 17.42 | Steps: 15 | Time: 1.18s\n",
      "Reward: 15.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 0. 1. 0.]\n",
      "Epi 13/200 | Avg Steps (last 100): 19.08 | Steps: 39 | Time: 1.31s\n",
      "Reward: 39.0\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\S3\\RL\\research project\\Generative-Reward-Decomposition-RL\\modules\\GenerativeModel.py:51: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  rew_losses.append(F.mse_loss(predicted_return, total_return))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epi 14/200 | Avg Steps (last 100): 18.71 | Steps: 14 | Time: 1.76s\n",
      "Reward: 14.0\n",
      "  Losses -> Gen: 130.1522 (Rew: 129.9789, Dyn: 0.1716, Reg: 0.0018)\n",
      "  Policy -> Actor: -0.2757, Critic: 0.0504\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 15/200 | Avg Steps (last 100): 18.60 | Steps: 17 | Time: 2.24s\n",
      "Reward: 17.0\n",
      "  Losses -> Gen: 23.7253 (Rew: 23.6523, Dyn: 0.0712, Reg: 0.0018)\n",
      "  Policy -> Actor: -0.9009, Critic: 0.1033\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 16/200 | Avg Steps (last 100): 18.25 | Steps: 13 | Time: 2.59s\n",
      "Reward: 13.0\n",
      "  Losses -> Gen: 2.1113 (Rew: 2.0972, Dyn: 0.0123, Reg: 0.0018)\n",
      "  Policy -> Actor: -1.3876, Critic: 0.2768\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 17/200 | Avg Steps (last 100): 18.06 | Steps: 15 | Time: 3.00s\n",
      "Reward: 15.0\n",
      "  Losses -> Gen: 10.8226 (Rew: 10.7975, Dyn: 0.0234, Reg: 0.0018)\n",
      "  Policy -> Actor: -1.5931, Critic: 0.0428\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 18/200 | Avg Steps (last 100): 17.56 | Steps: 9 | Time: 3.25s\n",
      "Reward: 9.0\n",
      "  Losses -> Gen: 5.7898 (Rew: 5.7709, Dyn: 0.0172, Reg: 0.0018)\n",
      "  Policy -> Actor: -1.6312, Critic: 0.1173\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 19/200 | Avg Steps (last 100): 18.21 | Steps: 30 | Time: 4.08s\n",
      "Reward: 30.0\n",
      "  Losses -> Gen: 6.4631 (Rew: 6.4501, Dyn: 0.0112, Reg: 0.0018)\n",
      "  Policy -> Actor: -1.7024, Critic: 0.0648\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 20/200 | Avg Steps (last 100): 18.15 | Steps: 17 | Time: 4.56s\n",
      "Reward: 17.0\n",
      "  Losses -> Gen: 3.0589 (Rew: 3.0498, Dyn: 0.0073, Reg: 0.0018)\n",
      "  Policy -> Actor: -1.7820, Critic: 0.0518\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.21']\n",
      "  Compact Mask: [0. 1. 0. 1.]\n",
      "Epi 21/200 | Avg Steps (last 100): 17.81 | Steps: 11 | Time: 4.88s\n",
      "Reward: 11.0\n",
      "  Losses -> Gen: 0.5057 (Rew: 0.4988, Dyn: 0.0051, Reg: 0.0018)\n",
      "  Policy -> Actor: -1.9275, Critic: 0.0390\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 0. 1.]\n",
      "Epi 22/200 | Avg Steps (last 100): 17.95 | Steps: 21 | Time: 5.48s\n",
      "Reward: 21.0\n",
      "  Losses -> Gen: 0.6144 (Rew: 0.6039, Dyn: 0.0088, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.0019, Critic: 0.1311\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 23/200 | Avg Steps (last 100): 18.61 | Steps: 33 | Time: 6.43s\n",
      "Reward: 33.0\n",
      "  Losses -> Gen: 0.4539 (Rew: 0.4380, Dyn: 0.0141, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.1956, Critic: 0.0974\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 24/200 | Avg Steps (last 100): 18.33 | Steps: 12 | Time: 6.80s\n",
      "Reward: 12.0\n",
      "  Losses -> Gen: 7.2119 (Rew: 7.2026, Dyn: 0.0075, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.3070, Critic: 0.1286\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 25/200 | Avg Steps (last 100): 18.20 | Steps: 15 | Time: 7.22s\n",
      "Reward: 15.0\n",
      "  Losses -> Gen: 3.6633 (Rew: 3.6516, Dyn: 0.0099, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.3163, Critic: 0.1525\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.67', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 26/200 | Avg Steps (last 100): 18.15 | Steps: 17 | Time: 7.71s\n",
      "Reward: 17.0\n",
      "  Losses -> Gen: 2.1845 (Rew: 2.1734, Dyn: 0.0094, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.3541, Critic: 0.1106\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 27/200 | Avg Steps (last 100): 18.15 | Steps: 18 | Time: 8.21s\n",
      "Reward: 18.0\n",
      "  Losses -> Gen: 1.8977 (Rew: 1.8854, Dyn: 0.0105, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.4736, Critic: 0.1741\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 28/200 | Avg Steps (last 100): 18.04 | Steps: 15 | Time: 8.63s\n",
      "Reward: 15.0\n",
      "  Losses -> Gen: 0.7967 (Rew: 0.7654, Dyn: 0.0295, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.4681, Critic: 0.1455\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 29/200 | Avg Steps (last 100): 18.38 | Steps: 28 | Time: 9.40s\n",
      "Reward: 28.0\n",
      "  Losses -> Gen: 0.0908 (Rew: 0.0816, Dyn: 0.0075, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.6515, Critic: 0.1515\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 0. 0. 1.]\n",
      "Epi 30/200 | Avg Steps (last 100): 18.67 | Steps: 27 | Time: 10.17s\n",
      "Reward: 27.0\n",
      "  Losses -> Gen: 5.6371 (Rew: 5.6048, Dyn: 0.0305, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.7725, Critic: 0.2115\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 0. 1. 0.]\n",
      "Epi 31/200 | Avg Steps (last 100): 18.58 | Steps: 16 | Time: 10.63s\n",
      "Reward: 16.0\n",
      "  Losses -> Gen: 1.9414 (Rew: 1.8663, Dyn: 0.0733, Reg: 0.0018)\n",
      "  Policy -> Actor: -2.8403, Critic: 0.3007\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 32/200 | Avg Steps (last 100): 18.84 | Steps: 27 | Time: 11.38s\n",
      "Reward: 27.0\n",
      "  Losses -> Gen: 10.3950 (Rew: 10.3836, Dyn: 0.0096, Reg: 0.0018)\n",
      "  Policy -> Actor: -3.0389, Critic: 0.2041\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 33/200 | Avg Steps (last 100): 19.39 | Steps: 37 | Time: 12.40s\n",
      "Reward: 37.0\n",
      "  Losses -> Gen: 1.3370 (Rew: 1.2812, Dyn: 0.0539, Reg: 0.0018)\n",
      "  Policy -> Actor: -3.1486, Critic: 0.2749\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 34/200 | Avg Steps (last 100): 20.18 | Steps: 46 | Time: 13.67s\n",
      "Reward: 46.0\n",
      "  Losses -> Gen: 0.1695 (Rew: 0.1620, Dyn: 0.0057, Reg: 0.0018)\n",
      "  Policy -> Actor: -3.3874, Critic: 0.2811\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 35/200 | Avg Steps (last 100): 20.11 | Steps: 18 | Time: 14.16s\n",
      "Reward: 18.0\n",
      "  Losses -> Gen: 0.8132 (Rew: 0.8017, Dyn: 0.0097, Reg: 0.0018)\n",
      "  Policy -> Actor: -3.4954, Critic: 0.2790\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 36/200 | Avg Steps (last 100): 20.19 | Steps: 23 | Time: 14.79s\n",
      "Reward: 23.0\n",
      "  Losses -> Gen: 0.5583 (Rew: 0.5414, Dyn: 0.0150, Reg: 0.0018)\n",
      "  Policy -> Actor: -3.6244, Critic: 0.2238\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 37/200 | Avg Steps (last 100): 20.27 | Steps: 23 | Time: 15.42s\n",
      "Reward: 23.0\n",
      "  Losses -> Gen: 1.7208 (Rew: 1.7156, Dyn: 0.0033, Reg: 0.0018)\n",
      "  Policy -> Actor: -3.6884, Critic: 0.3993\n",
      "  Causal Probs (S->R): ['0.15', '0.61', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 38/200 | Avg Steps (last 100): 20.76 | Steps: 39 | Time: 16.50s\n",
      "Reward: 39.0\n",
      "  Losses -> Gen: 0.4519 (Rew: 0.4455, Dyn: 0.0046, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.0127, Critic: 0.6875\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.68', '0.21']\n",
      "  Compact Mask: [0. 0. 0. 0.]\n",
      "Epi 39/200 | Avg Steps (last 100): 20.67 | Steps: 17 | Time: 16.97s\n",
      "Reward: 17.0\n",
      "  Losses -> Gen: 5.1161 (Rew: 5.0970, Dyn: 0.0173, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.0273, Critic: 0.4272\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 40/200 | Avg Steps (last 100): 21.48 | Steps: 53 | Time: 18.43s\n",
      "Reward: 53.0\n",
      "  Losses -> Gen: 2.0149 (Rew: 2.0083, Dyn: 0.0048, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.2898, Critic: 0.5424\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 41/200 | Avg Steps (last 100): 21.17 | Steps: 9 | Time: 18.70s\n",
      "Reward: 9.0\n",
      "  Losses -> Gen: 1.7053 (Rew: 1.6991, Dyn: 0.0044, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.1257, Critic: 0.6428\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 42/200 | Avg Steps (last 100): 21.14 | Steps: 20 | Time: 19.26s\n",
      "Reward: 20.0\n",
      "  Losses -> Gen: 0.5935 (Rew: 0.5369, Dyn: 0.0549, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.3607, Critic: 0.5592\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.68', '0.21']\n",
      "  Compact Mask: [0. 1. 1. 1.]\n",
      "Epi 43/200 | Avg Steps (last 100): 21.12 | Steps: 20 | Time: 19.82s\n",
      "Reward: 20.0\n",
      "  Losses -> Gen: 2.4578 (Rew: 2.4491, Dyn: 0.0069, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.5453, Critic: 0.4414\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.21']\n",
      "  Compact Mask: [0. 0. 0. 0.]\n",
      "Epi 44/200 | Avg Steps (last 100): 21.11 | Steps: 21 | Time: 20.39s\n",
      "Reward: 21.0\n",
      "  Losses -> Gen: 0.2672 (Rew: 0.2498, Dyn: 0.0156, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.4340, Critic: 0.4986\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.21']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 45/200 | Avg Steps (last 100): 20.91 | Steps: 12 | Time: 20.72s\n",
      "Reward: 12.0\n",
      "  Losses -> Gen: 2.1955 (Rew: 2.1780, Dyn: 0.0157, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.7676, Critic: 0.5204\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.68', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 46/200 | Avg Steps (last 100): 20.78 | Steps: 15 | Time: 21.13s\n",
      "Reward: 15.0\n",
      "  Losses -> Gen: 0.4953 (Rew: 0.4769, Dyn: 0.0166, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.7436, Critic: 0.5955\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 47/200 | Avg Steps (last 100): 20.83 | Steps: 23 | Time: 21.76s\n",
      "Reward: 23.0\n",
      "  Losses -> Gen: 0.6295 (Rew: 0.6205, Dyn: 0.0072, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.5832, Critic: 0.7052\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 48/200 | Avg Steps (last 100): 21.00 | Steps: 29 | Time: 22.55s\n",
      "Reward: 29.0\n",
      "  Losses -> Gen: 0.7792 (Rew: 0.7729, Dyn: 0.0044, Reg: 0.0018)\n",
      "  Policy -> Actor: -4.7874, Critic: 1.0999\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 49/200 | Avg Steps (last 100): 21.22 | Steps: 32 | Time: 23.42s\n",
      "Reward: 32.0\n",
      "  Losses -> Gen: 2.6294 (Rew: 2.6235, Dyn: 0.0040, Reg: 0.0018)\n",
      "  Policy -> Actor: -5.0310, Critic: 0.5800\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.21']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 50/200 | Avg Steps (last 100): 21.10 | Steps: 15 | Time: 23.84s\n",
      "Reward: 15.0\n",
      "  Losses -> Gen: 2.4905 (Rew: 2.4699, Dyn: 0.0188, Reg: 0.0018)\n",
      "  Policy -> Actor: -5.1695, Critic: 0.4298\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.21']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 51/200 | Avg Steps (last 100): 21.29 | Steps: 31 | Time: 24.68s\n",
      "Reward: 31.0\n",
      "  Losses -> Gen: 1.4989 (Rew: 1.4899, Dyn: 0.0072, Reg: 0.0018)\n",
      "  Policy -> Actor: -5.2415, Critic: 0.6819\n",
      "  Causal Probs (S->R): ['0.15', '0.62', '0.69', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 52/200 | Avg Steps (last 100): 22.08 | Steps: 62 | Time: 26.42s\n",
      "Reward: 62.0\n",
      "  Losses -> Gen: 1.2701 (Rew: 1.2616, Dyn: 0.0066, Reg: 0.0018)\n",
      "  Policy -> Actor: -5.5205, Critic: 0.3273\n",
      "  Causal Probs (S->R): ['0.16', '0.62', '0.70', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 53/200 | Avg Steps (last 100): 22.55 | Steps: 47 | Time: 27.70s\n",
      "Reward: 47.0\n",
      "  Losses -> Gen: 0.5538 (Rew: 0.5493, Dyn: 0.0026, Reg: 0.0019)\n",
      "  Policy -> Actor: -5.8266, Critic: 0.4201\n",
      "  Causal Probs (S->R): ['0.16', '0.63', '0.70', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 54/200 | Avg Steps (last 100): 22.56 | Steps: 23 | Time: 28.34s\n",
      "Reward: 23.0\n",
      "  Losses -> Gen: 0.3022 (Rew: 0.2862, Dyn: 0.0141, Reg: 0.0019)\n",
      "  Policy -> Actor: -5.9097, Critic: 0.7132\n",
      "  Causal Probs (S->R): ['0.16', '0.63', '0.70', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 55/200 | Avg Steps (last 100): 23.27 | Steps: 62 | Time: 30.13s\n",
      "Reward: 62.0\n",
      "  Losses -> Gen: 3.9467 (Rew: 3.9395, Dyn: 0.0053, Reg: 0.0019)\n",
      "  Policy -> Actor: -6.1602, Critic: 0.9832\n",
      "  Causal Probs (S->R): ['0.16', '0.63', '0.71', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 56/200 | Avg Steps (last 100): 23.09 | Steps: 13 | Time: 30.50s\n",
      "Reward: 13.0\n",
      "  Losses -> Gen: 0.8869 (Rew: 0.8703, Dyn: 0.0148, Reg: 0.0019)\n",
      "  Policy -> Actor: -6.5441, Critic: 2.1447\n",
      "  Causal Probs (S->R): ['0.16', '0.63', '0.71', '0.22']\n",
      "  Compact Mask: [1. 0. 1. 0.]\n",
      "Epi 57/200 | Avg Steps (last 100): 23.65 | Steps: 55 | Time: 32.11s\n",
      "Reward: 55.0\n",
      "  Losses -> Gen: 3.8860 (Rew: 3.8750, Dyn: 0.0090, Reg: 0.0019)\n",
      "  Policy -> Actor: -6.3224, Critic: 1.0904\n",
      "  Causal Probs (S->R): ['0.16', '0.63', '0.71', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 58/200 | Avg Steps (last 100): 23.71 | Steps: 27 | Time: 32.87s\n",
      "Reward: 27.0\n",
      "  Losses -> Gen: 1.2511 (Rew: 1.2389, Dyn: 0.0103, Reg: 0.0019)\n",
      "  Policy -> Actor: -6.6934, Critic: 1.0315\n",
      "  Causal Probs (S->R): ['0.16', '0.63', '0.72', '0.22']\n",
      "  Compact Mask: [0. 1. 1. 1.]\n",
      "Epi 59/200 | Avg Steps (last 100): 24.31 | Steps: 59 | Time: 34.52s\n",
      "Reward: 59.0\n",
      "  Losses -> Gen: 2.8056 (Rew: 2.7773, Dyn: 0.0264, Reg: 0.0019)\n",
      "  Policy -> Actor: -6.8995, Critic: 0.5481\n",
      "  Causal Probs (S->R): ['0.16', '0.64', '0.72', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 60/200 | Avg Steps (last 100): 24.98 | Steps: 65 | Time: 36.35s\n",
      "Reward: 65.0\n",
      "  Losses -> Gen: 0.3615 (Rew: 0.3559, Dyn: 0.0037, Reg: 0.0019)\n",
      "  Policy -> Actor: -6.9102, Critic: 0.9956\n",
      "  Causal Probs (S->R): ['0.16', '0.64', '0.72', '0.22']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 61/200 | Avg Steps (last 100): 25.48 | Steps: 55 | Time: 37.90s\n",
      "Reward: 55.0\n",
      "  Losses -> Gen: 0.0864 (Rew: 0.0810, Dyn: 0.0035, Reg: 0.0020)\n",
      "  Policy -> Actor: -7.4916, Critic: 0.8929\n",
      "  Causal Probs (S->R): ['0.16', '0.65', '0.73', '0.22']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 62/200 | Avg Steps (last 100): 26.50 | Steps: 89 | Time: 40.35s\n",
      "Reward: 89.0\n",
      "  Losses -> Gen: 0.9696 (Rew: 0.9629, Dyn: 0.0047, Reg: 0.0020)\n",
      "  Policy -> Actor: -8.1142, Critic: 0.9576\n",
      "  Causal Probs (S->R): ['0.16', '0.65', '0.74', '0.23']\n",
      "  Compact Mask: [0. 1. 1. 1.]\n",
      "Epi 63/200 | Avg Steps (last 100): 26.87 | Steps: 50 | Time: 41.72s\n",
      "Reward: 50.0\n",
      "  Losses -> Gen: 31.1776 (Rew: 31.1680, Dyn: 0.0076, Reg: 0.0020)\n",
      "  Policy -> Actor: -8.5032, Critic: 0.7039\n",
      "  Causal Probs (S->R): ['0.16', '0.66', '0.74', '0.23']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 64/200 | Avg Steps (last 100): 27.67 | Steps: 78 | Time: 43.87s\n",
      "Reward: 78.0\n",
      "  Losses -> Gen: 50.6950 (Rew: 50.6867, Dyn: 0.0062, Reg: 0.0020)\n",
      "  Policy -> Actor: -8.5125, Critic: 1.2747\n",
      "  Causal Probs (S->R): ['0.16', '0.66', '0.75', '0.23']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 65/200 | Avg Steps (last 100): 29.11 | Steps: 121 | Time: 47.30s\n",
      "Reward: 121.0\n",
      "  Losses -> Gen: 14.3735 (Rew: 14.3680, Dyn: 0.0035, Reg: 0.0021)\n",
      "  Policy -> Actor: -9.5726, Critic: 0.5037\n",
      "  Causal Probs (S->R): ['0.16', '0.66', '0.77', '0.24']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 66/200 | Avg Steps (last 100): 29.86 | Steps: 79 | Time: 49.54s\n",
      "Reward: 79.0\n",
      "  Losses -> Gen: 9.5489 (Rew: 9.5376, Dyn: 0.0092, Reg: 0.0021)\n",
      "  Policy -> Actor: -9.7254, Critic: 0.8330\n",
      "  Causal Probs (S->R): ['0.17', '0.67', '0.78', '0.24']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 67/200 | Avg Steps (last 100): 30.22 | Steps: 54 | Time: 51.09s\n",
      "Reward: 54.0\n",
      "  Losses -> Gen: 7.9893 (Rew: 7.9813, Dyn: 0.0059, Reg: 0.0021)\n",
      "  Policy -> Actor: -10.2254, Critic: 0.8489\n",
      "  Causal Probs (S->R): ['0.17', '0.67', '0.78', '0.25']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 68/200 | Avg Steps (last 100): 30.84 | Steps: 72 | Time: 53.10s\n",
      "Reward: 72.0\n",
      "  Losses -> Gen: 0.6859 (Rew: 0.6755, Dyn: 0.0083, Reg: 0.0022)\n",
      "  Policy -> Actor: -10.2685, Critic: 4.1881\n",
      "  Causal Probs (S->R): ['0.17', '0.68', '0.79', '0.25']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 69/200 | Avg Steps (last 100): 33.62 | Steps: 223 | Time: 59.29s\n",
      "Reward: 223.0\n",
      "  Losses -> Gen: 103.2881 (Rew: 103.2793, Dyn: 0.0066, Reg: 0.0022)\n",
      "  Policy -> Actor: -11.7251, Critic: 0.6018\n",
      "  Causal Probs (S->R): ['0.17', '0.69', '0.81', '0.26']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 70/200 | Avg Steps (last 100): 34.27 | Steps: 79 | Time: 61.49s\n",
      "Reward: 79.0\n",
      "  Losses -> Gen: 21.4885 (Rew: 21.4817, Dyn: 0.0045, Reg: 0.0023)\n",
      "  Policy -> Actor: -12.4364, Critic: 1.3674\n",
      "  Causal Probs (S->R): ['0.18', '0.69', '0.81', '0.27']\n",
      "  Compact Mask: [0. 0. 1. 0.]\n",
      "Epi 71/200 | Avg Steps (last 100): 35.03 | Steps: 88 | Time: 63.91s\n",
      "Reward: 88.0\n",
      "  Losses -> Gen: 4.1677 (Rew: 4.1550, Dyn: 0.0104, Reg: 0.0023)\n",
      "  Policy -> Actor: -12.5932, Critic: 1.7581\n",
      "  Causal Probs (S->R): ['0.18', '0.69', '0.82', '0.27']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 72/200 | Avg Steps (last 100): 36.04 | Steps: 108 | Time: 66.98s\n",
      "Reward: 108.0\n",
      "  Losses -> Gen: 18.8137 (Rew: 18.8044, Dyn: 0.0070, Reg: 0.0023)\n",
      "  Policy -> Actor: -13.7427, Critic: 3.7604\n",
      "  Causal Probs (S->R): ['0.18', '0.70', '0.83', '0.27']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 73/200 | Avg Steps (last 100): 36.74 | Steps: 87 | Time: 69.43s\n",
      "Reward: 87.0\n",
      "  Losses -> Gen: 6.1851 (Rew: 6.1688, Dyn: 0.0139, Reg: 0.0024)\n",
      "  Policy -> Actor: -15.5463, Critic: 6.2847\n",
      "  Causal Probs (S->R): ['0.18', '0.70', '0.84', '0.28']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 74/200 | Avg Steps (last 100): 37.47 | Steps: 91 | Time: 71.99s\n",
      "Reward: 91.0\n",
      "  Losses -> Gen: 47.0788 (Rew: 47.0699, Dyn: 0.0065, Reg: 0.0024)\n",
      "  Policy -> Actor: -13.9724, Critic: 1.3994\n",
      "  Causal Probs (S->R): ['0.19', '0.70', '0.84', '0.28']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 75/200 | Avg Steps (last 100): 37.99 | Steps: 76 | Time: 74.10s\n",
      "Reward: 76.0\n",
      "  Losses -> Gen: 48.8195 (Rew: 48.8094, Dyn: 0.0078, Reg: 0.0024)\n",
      "  Policy -> Actor: -14.4829, Critic: 1.0657\n",
      "  Causal Probs (S->R): ['0.19', '0.70', '0.85', '0.28']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 76/200 | Avg Steps (last 100): 38.26 | Steps: 59 | Time: 75.73s\n",
      "Reward: 59.0\n",
      "  Losses -> Gen: 86.3497 (Rew: 86.3350, Dyn: 0.0124, Reg: 0.0024)\n",
      "  Policy -> Actor: -15.0699, Critic: 0.6280\n",
      "  Causal Probs (S->R): ['0.19', '0.70', '0.85', '0.28']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 77/200 | Avg Steps (last 100): 38.66 | Steps: 69 | Time: 77.67s\n",
      "Reward: 69.0\n",
      "  Losses -> Gen: 2.8252 (Rew: 2.8168, Dyn: 0.0059, Reg: 0.0025)\n",
      "  Policy -> Actor: -15.8121, Critic: 1.1830\n",
      "  Causal Probs (S->R): ['0.19', '0.70', '0.85', '0.28']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 78/200 | Avg Steps (last 100): 39.28 | Steps: 87 | Time: 80.05s\n",
      "Reward: 87.0\n",
      "  Losses -> Gen: 2.7187 (Rew: 2.7133, Dyn: 0.0030, Reg: 0.0025)\n",
      "  Policy -> Actor: -15.5322, Critic: 0.7086\n",
      "  Causal Probs (S->R): ['0.19', '0.71', '0.86', '0.29']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 79/200 | Avg Steps (last 100): 39.71 | Steps: 73 | Time: 82.08s\n",
      "Reward: 73.0\n",
      "  Losses -> Gen: 181.5023 (Rew: 181.4857, Dyn: 0.0141, Reg: 0.0025)\n",
      "  Policy -> Actor: -16.3837, Critic: 3.2817\n",
      "  Causal Probs (S->R): ['0.20', '0.71', '0.86', '0.29']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 80/200 | Avg Steps (last 100): 41.45 | Steps: 179 | Time: 86.99s\n",
      "Reward: 179.0\n",
      "  Losses -> Gen: 1714.2869 (Rew: 1714.2640, Dyn: 0.0202, Reg: 0.0025)\n",
      "  Policy -> Actor: -17.4019, Critic: 6.4422\n",
      "  Causal Probs (S->R): ['0.20', '0.71', '0.87', '0.29']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 81/200 | Avg Steps (last 100): 41.80 | Steps: 70 | Time: 88.92s\n",
      "Reward: 70.0\n",
      "  Losses -> Gen: 106.9514 (Rew: 106.9426, Dyn: 0.0062, Reg: 0.0025)\n",
      "  Policy -> Actor: -17.8860, Critic: 3.3420\n",
      "  Causal Probs (S->R): ['0.19', '0.72', '0.87', '0.29']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 82/200 | Avg Steps (last 100): 42.87 | Steps: 129 | Time: 92.56s\n",
      "Reward: 129.0\n",
      "  Losses -> Gen: 2071.2742 (Rew: 2071.2681, Dyn: 0.0034, Reg: 0.0026)\n",
      "  Policy -> Actor: -18.7868, Critic: 1.3570\n",
      "  Causal Probs (S->R): ['0.19', '0.72', '0.88', '0.29']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 83/200 | Avg Steps (last 100): 43.35 | Steps: 83 | Time: 94.88s\n",
      "Reward: 83.0\n",
      "  Losses -> Gen: 570.2214 (Rew: 570.2163, Dyn: 0.0025, Reg: 0.0026)\n",
      "  Policy -> Actor: -19.0818, Critic: 1.0674\n",
      "  Causal Probs (S->R): ['0.19', '0.72', '0.88', '0.30']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 84/200 | Avg Steps (last 100): 43.93 | Steps: 92 | Time: 97.50s\n",
      "Reward: 92.0\n",
      "  Losses -> Gen: 72.1697 (Rew: 72.1514, Dyn: 0.0157, Reg: 0.0026)\n",
      "  Policy -> Actor: -19.5569, Critic: 1.2393\n",
      "  Causal Probs (S->R): ['0.18', '0.72', '0.89', '0.30']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 85/200 | Avg Steps (last 100): 44.39 | Steps: 83 | Time: 99.82s\n",
      "Reward: 83.0\n",
      "  Losses -> Gen: 350.5312 (Rew: 350.5259, Dyn: 0.0027, Reg: 0.0027)\n",
      "  Policy -> Actor: -20.0986, Critic: 0.9320\n",
      "  Causal Probs (S->R): ['0.18', '0.72', '0.89', '0.30']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 86/200 | Avg Steps (last 100): 44.92 | Steps: 90 | Time: 102.43s\n",
      "Reward: 90.0\n",
      "  Losses -> Gen: 9.2587 (Rew: 9.2428, Dyn: 0.0132, Reg: 0.0027)\n",
      "  Policy -> Actor: -20.1502, Critic: 1.2943\n",
      "  Causal Probs (S->R): ['0.18', '0.73', '0.90', '0.31']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 87/200 | Avg Steps (last 100): 45.45 | Steps: 91 | Time: 105.02s\n",
      "Reward: 91.0\n",
      "  Losses -> Gen: 262.3083 (Rew: 262.3033, Dyn: 0.0024, Reg: 0.0027)\n",
      "  Policy -> Actor: -24.8589, Critic: 12.6151\n",
      "  Causal Probs (S->R): ['0.18', '0.73', '0.90', '0.31']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 88/200 | Avg Steps (last 100): 46.58 | Steps: 145 | Time: 109.12s\n",
      "Reward: 145.0\n",
      "  Losses -> Gen: 29.3694 (Rew: 29.3603, Dyn: 0.0063, Reg: 0.0028)\n",
      "  Policy -> Actor: -22.4468, Critic: 1.8819\n",
      "  Causal Probs (S->R): ['0.18', '0.74', '0.91', '0.31']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 89/200 | Avg Steps (last 100): 47.58 | Steps: 136 | Time: 112.99s\n",
      "Reward: 136.0\n",
      "  Losses -> Gen: 1872.2220 (Rew: 1872.2158, Dyn: 0.0035, Reg: 0.0028)\n",
      "  Policy -> Actor: -22.5531, Critic: 5.1001\n",
      "  Causal Probs (S->R): ['0.18', '0.74', '0.91', '0.32']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 90/200 | Avg Steps (last 100): 48.23 | Steps: 106 | Time: 115.92s\n",
      "Reward: 106.0\n",
      "  Losses -> Gen: 26.5746 (Rew: 26.5692, Dyn: 0.0027, Reg: 0.0028)\n",
      "  Policy -> Actor: -23.5786, Critic: 1.2988\n",
      "  Causal Probs (S->R): ['0.18', '0.74', '0.91', '0.32']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 91/200 | Avg Steps (last 100): 48.88 | Steps: 107 | Time: 118.96s\n",
      "Reward: 107.0\n",
      "  Losses -> Gen: 126.7027 (Rew: 126.6943, Dyn: 0.0055, Reg: 0.0028)\n",
      "  Policy -> Actor: -22.8719, Critic: 1.4408\n",
      "  Causal Probs (S->R): ['0.18', '0.74', '0.92', '0.32']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 92/200 | Avg Steps (last 100): 49.82 | Steps: 135 | Time: 122.78s\n",
      "Reward: 135.0\n",
      "  Losses -> Gen: 26.6659 (Rew: 26.6515, Dyn: 0.0115, Reg: 0.0029)\n",
      "  Policy -> Actor: -23.5734, Critic: 1.4167\n",
      "  Causal Probs (S->R): ['0.18', '0.75', '0.92', '0.33']\n",
      "  Compact Mask: [0. 0. 0. 0.]\n",
      "Epi 93/200 | Avg Steps (last 100): 50.61 | Steps: 124 | Time: 126.27s\n",
      "Reward: 124.0\n",
      "  Losses -> Gen: 16.0022 (Rew: 15.9943, Dyn: 0.0050, Reg: 0.0029)\n",
      "  Policy -> Actor: -24.2638, Critic: 1.2231\n",
      "  Causal Probs (S->R): ['0.18', '0.75', '0.92', '0.33']\n",
      "  Compact Mask: [0. 0. 1. 0.]\n",
      "Epi 94/200 | Avg Steps (last 100): 51.53 | Steps: 137 | Time: 130.17s\n",
      "Reward: 137.0\n",
      "  Losses -> Gen: 3.7627 (Rew: 3.7517, Dyn: 0.0081, Reg: 0.0030)\n",
      "  Policy -> Actor: -23.5861, Critic: 1.1977\n",
      "  Causal Probs (S->R): ['0.18', '0.75', '0.93', '0.34']\n",
      "  Compact Mask: [0. 1. 1. 1.]\n",
      "Epi 95/200 | Avg Steps (last 100): 52.46 | Steps: 140 | Time: 134.18s\n",
      "Reward: 140.0\n",
      "  Losses -> Gen: 3.0135 (Rew: 3.0059, Dyn: 0.0046, Reg: 0.0030)\n",
      "  Policy -> Actor: -26.2940, Critic: 1.5824\n",
      "  Causal Probs (S->R): ['0.18', '0.75', '0.93', '0.34']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 96/200 | Avg Steps (last 100): 53.17 | Steps: 120 | Time: 137.52s\n",
      "Reward: 120.0\n",
      "  Losses -> Gen: 48.3545 (Rew: 48.3369, Dyn: 0.0145, Reg: 0.0030)\n",
      "  Policy -> Actor: -26.1799, Critic: 5.0686\n",
      "  Causal Probs (S->R): ['0.18', '0.76', '0.93', '0.35']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 97/200 | Avg Steps (last 100): 53.90 | Steps: 124 | Time: 140.96s\n",
      "Reward: 124.0\n",
      "  Losses -> Gen: 24.8061 (Rew: 24.7947, Dyn: 0.0083, Reg: 0.0031)\n",
      "  Policy -> Actor: -26.1918, Critic: 1.2228\n",
      "  Causal Probs (S->R): ['0.18', '0.76', '0.93', '0.35']\n",
      "  Compact Mask: [1. 1. 1. 0.]\n",
      "Epi 98/200 | Avg Steps (last 100): 55.30 | Steps: 191 | Time: 146.25s\n",
      "Reward: 191.0\n",
      "  Losses -> Gen: 9.1896 (Rew: 9.1818, Dyn: 0.0046, Reg: 0.0031)\n",
      "  Policy -> Actor: -29.4211, Critic: 9.0670\n",
      "  Causal Probs (S->R): ['0.19', '0.76', '0.94', '0.36']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 99/200 | Avg Steps (last 100): 55.83 | Steps: 108 | Time: 149.25s\n",
      "Reward: 108.0\n",
      "  Losses -> Gen: 1306.5746 (Rew: 1306.5696, Dyn: 0.0018, Reg: 0.0032)\n",
      "  Policy -> Actor: -28.5957, Critic: 1.1192\n",
      "  Causal Probs (S->R): ['0.19', '0.76', '0.94', '0.37']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 100/200 | Avg Steps (last 100): 56.87 | Steps: 160 | Time: 153.81s\n",
      "Reward: 160.0\n",
      "  Losses -> Gen: 31.1344 (Rew: 31.1287, Dyn: 0.0025, Reg: 0.0032)\n",
      "  Policy -> Actor: -29.8023, Critic: 1.8024\n",
      "  Causal Probs (S->R): ['0.20', '0.77', '0.94', '0.37']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 101/200 | Avg Steps (last 100): 58.47 | Steps: 173 | Time: 158.60s\n",
      "Reward: 173.0\n",
      "  Losses -> Gen: 29.9197 (Rew: 29.9016, Dyn: 0.0148, Reg: 0.0032)\n",
      "  Policy -> Actor: -29.6555, Critic: 1.7602\n",
      "  Causal Probs (S->R): ['0.20', '0.77', '0.94', '0.37']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 102/200 | Avg Steps (last 100): 59.84 | Steps: 155 | Time: 163.00s\n",
      "Reward: 155.0\n",
      "  Losses -> Gen: 6.5997 (Rew: 6.5842, Dyn: 0.0123, Reg: 0.0033)\n",
      "  Policy -> Actor: -30.7488, Critic: 2.4131\n",
      "  Causal Probs (S->R): ['0.20', '0.77', '0.95', '0.38']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 103/200 | Avg Steps (last 100): 61.46 | Steps: 172 | Time: 167.84s\n",
      "Reward: 172.0\n",
      "  Losses -> Gen: 9.7372 (Rew: 9.7271, Dyn: 0.0067, Reg: 0.0033)\n",
      "  Policy -> Actor: -31.7488, Critic: 2.3853\n",
      "  Causal Probs (S->R): ['0.21', '0.78', '0.95', '0.39']\n",
      "  Compact Mask: [0. 0. 1. 1.]\n",
      "Epi 104/200 | Avg Steps (last 100): 62.75 | Steps: 145 | Time: 171.83s\n",
      "Reward: 145.0\n",
      "  Losses -> Gen: 41.8744 (Rew: 41.8584, Dyn: 0.0127, Reg: 0.0033)\n",
      "  Policy -> Actor: -31.4753, Critic: 2.3665\n",
      "  Causal Probs (S->R): ['0.21', '0.78', '0.95', '0.39']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 105/200 | Avg Steps (last 100): 64.47 | Steps: 224 | Time: 177.98s\n",
      "Reward: 224.0\n",
      "  Losses -> Gen: 6.8075 (Rew: 6.7984, Dyn: 0.0057, Reg: 0.0034)\n",
      "  Policy -> Actor: -35.0138, Critic: 12.8252\n",
      "  Causal Probs (S->R): ['0.21', '0.78', '0.95', '0.40']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 106/200 | Avg Steps (last 100): 66.15 | Steps: 177 | Time: 183.02s\n",
      "Reward: 177.0\n",
      "  Losses -> Gen: 17.0615 (Rew: 17.0520, Dyn: 0.0060, Reg: 0.0034)\n",
      "  Policy -> Actor: -34.8250, Critic: 1.5396\n",
      "  Causal Probs (S->R): ['0.22', '0.78', '0.95', '0.41']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 107/200 | Avg Steps (last 100): 67.07 | Steps: 112 | Time: 186.16s\n",
      "Reward: 112.0\n",
      "  Losses -> Gen: 245.1090 (Rew: 245.0853, Dyn: 0.0202, Reg: 0.0035)\n",
      "  Policy -> Actor: -35.6141, Critic: 5.2557\n",
      "  Causal Probs (S->R): ['0.22', '0.78', '0.96', '0.41']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 108/200 | Avg Steps (last 100): 68.69 | Steps: 179 | Time: 191.15s\n",
      "Reward: 179.0\n",
      "  Losses -> Gen: 35.8120 (Rew: 35.7863, Dyn: 0.0222, Reg: 0.0035)\n",
      "  Policy -> Actor: -34.4939, Critic: 4.1548\n",
      "  Causal Probs (S->R): ['0.23', '0.78', '0.96', '0.42']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 109/200 | Avg Steps (last 100): 70.61 | Steps: 205 | Time: 196.86s\n",
      "Reward: 205.0\n",
      "  Losses -> Gen: 56.3548 (Rew: 56.3359, Dyn: 0.0154, Reg: 0.0036)\n",
      "  Policy -> Actor: -37.0472, Critic: 9.0897\n",
      "  Causal Probs (S->R): ['0.23', '0.78', '0.96', '0.43']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 110/200 | Avg Steps (last 100): 73.14 | Steps: 268 | Time: 204.25s\n",
      "Reward: 268.0\n",
      "  Losses -> Gen: 640.6039 (Rew: 640.5917, Dyn: 0.0086, Reg: 0.0036)\n",
      "  Policy -> Actor: -40.1452, Critic: 1.7605\n",
      "  Causal Probs (S->R): ['0.24', '0.79', '0.96', '0.44']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 111/200 | Avg Steps (last 100): 74.90 | Steps: 187 | Time: 209.58s\n",
      "Reward: 187.0\n",
      "  Losses -> Gen: 304.7373 (Rew: 304.7270, Dyn: 0.0067, Reg: 0.0037)\n",
      "  Policy -> Actor: -42.4977, Critic: 6.6213\n",
      "  Causal Probs (S->R): ['0.24', '0.79', '0.96', '0.45']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 112/200 | Avg Steps (last 100): 76.92 | Steps: 217 | Time: 215.59s\n",
      "Reward: 217.0\n",
      "  Losses -> Gen: 214.5676 (Rew: 214.5594, Dyn: 0.0045, Reg: 0.0037)\n",
      "  Policy -> Actor: -43.7883, Critic: 13.1147\n",
      "  Causal Probs (S->R): ['0.25', '0.79', '0.97', '0.46']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 113/200 | Avg Steps (last 100): 78.75 | Steps: 222 | Time: 221.74s\n",
      "Reward: 222.0\n",
      "  Losses -> Gen: 243.4685 (Rew: 243.4576, Dyn: 0.0071, Reg: 0.0038)\n",
      "  Policy -> Actor: -45.3548, Critic: 2.7880\n",
      "  Causal Probs (S->R): ['0.25', '0.79', '0.97', '0.47']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 114/200 | Avg Steps (last 100): 80.84 | Steps: 223 | Time: 227.95s\n",
      "Reward: 223.0\n",
      "  Losses -> Gen: 134.8126 (Rew: 134.8054, Dyn: 0.0033, Reg: 0.0038)\n",
      "  Policy -> Actor: -47.0585, Critic: 4.0646\n",
      "  Causal Probs (S->R): ['0.25', '0.79', '0.97', '0.48']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 115/200 | Avg Steps (last 100): 82.89 | Steps: 222 | Time: 234.09s\n",
      "Reward: 222.0\n",
      "  Losses -> Gen: 133.0026 (Rew: 132.9848, Dyn: 0.0139, Reg: 0.0039)\n",
      "  Policy -> Actor: -46.2930, Critic: 6.6083\n",
      "  Causal Probs (S->R): ['0.26', '0.80', '0.97', '0.49']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 116/200 | Avg Steps (last 100): 84.77 | Steps: 201 | Time: 241.76s\n",
      "Reward: 201.0\n",
      "  Losses -> Gen: 87.5894 (Rew: 87.5768, Dyn: 0.0087, Reg: 0.0039)\n",
      "  Policy -> Actor: -48.3055, Critic: 16.0311\n",
      "  Causal Probs (S->R): ['0.26', '0.80', '0.97', '0.50']\n",
      "  Compact Mask: [0. 0. 1. 1.]\n",
      "Epi 117/200 | Avg Steps (last 100): 87.30 | Steps: 268 | Time: 249.26s\n",
      "Reward: 268.0\n",
      "  Losses -> Gen: 635.3611 (Rew: 635.3530, Dyn: 0.0042, Reg: 0.0040)\n",
      "  Policy -> Actor: -50.0047, Critic: 15.5915\n",
      "  Causal Probs (S->R): ['0.27', '0.80', '0.97', '0.51']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 118/200 | Avg Steps (last 100): 90.09 | Steps: 288 | Time: 262.65s\n",
      "Reward: 288.0\n",
      "  Losses -> Gen: 135.9565 (Rew: 135.9448, Dyn: 0.0077, Reg: 0.0040)\n",
      "  Policy -> Actor: -52.1821, Critic: 5.2806\n",
      "  Causal Probs (S->R): ['0.27', '0.80', '0.97', '0.53']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 119/200 | Avg Steps (last 100): 91.94 | Steps: 215 | Time: 273.43s\n",
      "Reward: 215.0\n",
      "  Losses -> Gen: 103.6565 (Rew: 103.6460, Dyn: 0.0064, Reg: 0.0041)\n",
      "  Policy -> Actor: -52.2641, Critic: 8.3211\n",
      "  Causal Probs (S->R): ['0.27', '0.81', '0.98', '0.54']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 120/200 | Avg Steps (last 100): 94.50 | Steps: 273 | Time: 286.70s\n",
      "Reward: 273.0\n",
      "  Losses -> Gen: 181.8628 (Rew: 181.8556, Dyn: 0.0030, Reg: 0.0042)\n",
      "  Policy -> Actor: -58.4488, Critic: 2.4048\n",
      "  Causal Probs (S->R): ['0.27', '0.81', '0.98', '0.55']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 121/200 | Avg Steps (last 100): 96.52 | Steps: 213 | Time: 297.19s\n",
      "Reward: 213.0\n",
      "  Losses -> Gen: 245.2819 (Rew: 245.2710, Dyn: 0.0067, Reg: 0.0042)\n",
      "  Policy -> Actor: -58.0504, Critic: 3.0636\n",
      "  Causal Probs (S->R): ['0.28', '0.81', '0.98', '0.56']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 122/200 | Avg Steps (last 100): 98.28 | Steps: 197 | Time: 307.84s\n",
      "Reward: 197.0\n",
      "  Losses -> Gen: 46.2498 (Rew: 46.2364, Dyn: 0.0091, Reg: 0.0042)\n",
      "  Policy -> Actor: -57.1491, Critic: 15.4442\n",
      "  Causal Probs (S->R): ['0.28', '0.81', '0.98', '0.56']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 123/200 | Avg Steps (last 100): 99.82 | Steps: 187 | Time: 317.93s\n",
      "Reward: 187.0\n",
      "  Losses -> Gen: 529.5384 (Rew: 529.5289, Dyn: 0.0052, Reg: 0.0043)\n",
      "  Policy -> Actor: -60.2040, Critic: 18.6869\n",
      "  Causal Probs (S->R): ['0.28', '0.81', '0.98', '0.57']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 124/200 | Avg Steps (last 100): 101.76 | Steps: 206 | Time: 328.99s\n",
      "Reward: 206.0\n",
      "  Losses -> Gen: 16.7249 (Rew: 16.7114, Dyn: 0.0091, Reg: 0.0043)\n",
      "  Policy -> Actor: -60.6027, Critic: 6.6958\n",
      "  Causal Probs (S->R): ['0.29', '0.82', '0.98', '0.58']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 125/200 | Avg Steps (last 100): 103.93 | Steps: 232 | Time: 341.06s\n",
      "Reward: 232.0\n",
      "  Losses -> Gen: 606.6564 (Rew: 606.6422, Dyn: 0.0098, Reg: 0.0044)\n",
      "  Policy -> Actor: -63.4289, Critic: 15.4531\n",
      "  Causal Probs (S->R): ['0.29', '0.82', '0.98', '0.59']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 126/200 | Avg Steps (last 100): 105.71 | Steps: 195 | Time: 350.71s\n",
      "Reward: 195.0\n",
      "  Losses -> Gen: 63.9965 (Rew: 63.9881, Dyn: 0.0040, Reg: 0.0044)\n",
      "  Policy -> Actor: -64.5151, Critic: 13.3869\n",
      "  Causal Probs (S->R): ['0.29', '0.82', '0.98', '0.60']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 127/200 | Avg Steps (last 100): 107.80 | Steps: 227 | Time: 361.99s\n",
      "Reward: 227.0\n",
      "  Losses -> Gen: 74.6926 (Rew: 74.6820, Dyn: 0.0061, Reg: 0.0044)\n",
      "  Policy -> Actor: -69.2023, Critic: 19.8201\n",
      "  Causal Probs (S->R): ['0.30', '0.82', '0.98', '0.60']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 128/200 | Avg Steps (last 100): 110.16 | Steps: 251 | Time: 370.18s\n",
      "Reward: 251.0\n",
      "  Losses -> Gen: 85.3965 (Rew: 85.3874, Dyn: 0.0046, Reg: 0.0045)\n",
      "  Policy -> Actor: -66.9415, Critic: 12.0583\n",
      "  Causal Probs (S->R): ['0.30', '0.82', '0.98', '0.61']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 129/200 | Avg Steps (last 100): 112.03 | Steps: 215 | Time: 380.88s\n",
      "Reward: 215.0\n",
      "  Losses -> Gen: 89.5707 (Rew: 89.5490, Dyn: 0.0172, Reg: 0.0045)\n",
      "  Policy -> Actor: -70.1989, Critic: 16.6537\n",
      "  Causal Probs (S->R): ['0.31', '0.83', '0.98', '0.61']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 130/200 | Avg Steps (last 100): 113.83 | Steps: 207 | Time: 388.20s\n",
      "Reward: 207.0\n",
      "  Losses -> Gen: 133.3009 (Rew: 133.2862, Dyn: 0.0101, Reg: 0.0046)\n",
      "  Policy -> Actor: -68.8177, Critic: 19.6415\n",
      "  Causal Probs (S->R): ['0.31', '0.83', '0.98', '0.62']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 131/200 | Avg Steps (last 100): 115.92 | Steps: 225 | Time: 396.78s\n",
      "Reward: 225.0\n",
      "  Losses -> Gen: 148.2668 (Rew: 148.2588, Dyn: 0.0034, Reg: 0.0046)\n",
      "  Policy -> Actor: -71.4931, Critic: 11.1295\n",
      "  Causal Probs (S->R): ['0.32', '0.83', '0.98', '0.63']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 132/200 | Avg Steps (last 100): 117.77 | Steps: 212 | Time: 407.68s\n",
      "Reward: 212.0\n",
      "  Losses -> Gen: 764.7120 (Rew: 764.7024, Dyn: 0.0050, Reg: 0.0047)\n",
      "  Policy -> Actor: -72.7132, Critic: 45.9185\n",
      "  Causal Probs (S->R): ['0.32', '0.83', '0.98', '0.63']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 133/200 | Avg Steps (last 100): 119.47 | Steps: 207 | Time: 417.77s\n",
      "Reward: 207.0\n",
      "  Losses -> Gen: 128.6676 (Rew: 128.6595, Dyn: 0.0034, Reg: 0.0047)\n",
      "  Policy -> Actor: -77.4909, Critic: 16.2119\n",
      "  Causal Probs (S->R): ['0.33', '0.83', '0.98', '0.64']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 134/200 | Avg Steps (last 100): 121.14 | Steps: 213 | Time: 423.51s\n",
      "Reward: 213.0\n",
      "  Losses -> Gen: 623.2166 (Rew: 623.2011, Dyn: 0.0108, Reg: 0.0047)\n",
      "  Policy -> Actor: -76.4946, Critic: 12.8236\n",
      "  Causal Probs (S->R): ['0.33', '0.83', '0.98', '0.65']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 135/200 | Avg Steps (last 100): 122.72 | Steps: 176 | Time: 428.37s\n",
      "Reward: 176.0\n",
      "  Losses -> Gen: 240.5509 (Rew: 240.5373, Dyn: 0.0089, Reg: 0.0048)\n",
      "  Policy -> Actor: -75.5988, Critic: 11.1357\n",
      "  Causal Probs (S->R): ['0.33', '0.84', '0.98', '0.65']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 136/200 | Avg Steps (last 100): 124.34 | Steps: 185 | Time: 433.44s\n",
      "Reward: 185.0\n",
      "  Losses -> Gen: 322.2692 (Rew: 322.2599, Dyn: 0.0045, Reg: 0.0048)\n",
      "  Policy -> Actor: -77.4256, Critic: 17.8108\n",
      "  Causal Probs (S->R): ['0.34', '0.84', '0.99', '0.66']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 137/200 | Avg Steps (last 100): 126.01 | Steps: 190 | Time: 438.68s\n",
      "Reward: 190.0\n",
      "  Losses -> Gen: 109.2169 (Rew: 109.2072, Dyn: 0.0048, Reg: 0.0049)\n",
      "  Policy -> Actor: -78.9137, Critic: 70.6321\n",
      "  Causal Probs (S->R): ['0.34', '0.84', '0.99', '0.66']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 138/200 | Avg Steps (last 100): 127.91 | Steps: 229 | Time: 445.08s\n",
      "Reward: 229.0\n",
      "  Losses -> Gen: 57.7234 (Rew: 57.7157, Dyn: 0.0028, Reg: 0.0049)\n",
      "  Policy -> Actor: -81.5719, Critic: 18.7639\n",
      "  Causal Probs (S->R): ['0.35', '0.84', '0.99', '0.66']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 139/200 | Avg Steps (last 100): 129.62 | Steps: 188 | Time: 454.75s\n",
      "Reward: 188.0\n",
      "  Losses -> Gen: 40.9528 (Rew: 40.9433, Dyn: 0.0046, Reg: 0.0049)\n",
      "  Policy -> Actor: -83.0303, Critic: 9.7390\n",
      "  Causal Probs (S->R): ['0.35', '0.85', '0.99', '0.67']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 140/200 | Avg Steps (last 100): 131.06 | Steps: 197 | Time: 462.20s\n",
      "Reward: 197.0\n",
      "  Losses -> Gen: 65.0111 (Rew: 65.0009, Dyn: 0.0053, Reg: 0.0050)\n",
      "  Policy -> Actor: -82.5845, Critic: 15.7897\n",
      "  Causal Probs (S->R): ['0.36', '0.85', '0.99', '0.67']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 141/200 | Avg Steps (last 100): 132.79 | Steps: 182 | Time: 467.54s\n",
      "Reward: 182.0\n",
      "  Losses -> Gen: 81.2945 (Rew: 81.2834, Dyn: 0.0062, Reg: 0.0050)\n",
      "  Policy -> Actor: -81.4128, Critic: 17.6901\n",
      "  Causal Probs (S->R): ['0.37', '0.85', '0.99', '0.68']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 142/200 | Avg Steps (last 100): 134.65 | Steps: 206 | Time: 474.99s\n",
      "Reward: 206.0\n",
      "  Losses -> Gen: 164.3690 (Rew: 164.3602, Dyn: 0.0037, Reg: 0.0050)\n",
      "  Policy -> Actor: -84.4187, Critic: 9.2846\n",
      "  Causal Probs (S->R): ['0.37', '0.85', '0.99', '0.68']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 143/200 | Avg Steps (last 100): 136.36 | Steps: 191 | Time: 481.38s\n",
      "Reward: 191.0\n",
      "  Losses -> Gen: 53.3424 (Rew: 53.3347, Dyn: 0.0027, Reg: 0.0051)\n",
      "  Policy -> Actor: -88.4883, Critic: 10.0311\n",
      "  Causal Probs (S->R): ['0.38', '0.85', '0.99', '0.68']\n",
      "  Compact Mask: [1. 0. 1. 1.]\n",
      "Epi 144/200 | Avg Steps (last 100): 138.06 | Steps: 191 | Time: 490.40s\n",
      "Reward: 191.0\n",
      "  Losses -> Gen: 97.2527 (Rew: 97.2446, Dyn: 0.0030, Reg: 0.0051)\n",
      "  Policy -> Actor: -86.9403, Critic: 9.7428\n",
      "  Causal Probs (S->R): ['0.38', '0.86', '0.99', '0.68']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 145/200 | Avg Steps (last 100): 139.67 | Steps: 173 | Time: 498.37s\n",
      "Reward: 173.0\n",
      "  Losses -> Gen: 545.7953 (Rew: 545.7789, Dyn: 0.0113, Reg: 0.0051)\n",
      "  Policy -> Actor: -89.0019, Critic: 14.8506\n",
      "  Causal Probs (S->R): ['0.39', '0.86', '0.99', '0.69']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 146/200 | Avg Steps (last 100): 141.48 | Steps: 196 | Time: 507.46s\n",
      "Reward: 196.0\n",
      "  Losses -> Gen: 109.9069 (Rew: 109.8995, Dyn: 0.0023, Reg: 0.0052)\n",
      "  Policy -> Actor: -93.4146, Critic: 68.6096\n",
      "  Causal Probs (S->R): ['0.40', '0.86', '0.99', '0.70']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 147/200 | Avg Steps (last 100): 143.25 | Steps: 200 | Time: 516.68s\n",
      "Reward: 200.0\n",
      "  Losses -> Gen: 269.4168 (Rew: 269.3889, Dyn: 0.0228, Reg: 0.0052)\n",
      "  Policy -> Actor: -94.1001, Critic: 5.3468\n",
      "  Causal Probs (S->R): ['0.40', '0.86', '0.99', '0.70']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 148/200 | Avg Steps (last 100): 145.21 | Steps: 225 | Time: 526.85s\n",
      "Reward: 225.0\n",
      "  Losses -> Gen: 162.4980 (Rew: 162.4900, Dyn: 0.0027, Reg: 0.0053)\n",
      "  Policy -> Actor: -91.7393, Critic: 9.5294\n",
      "  Causal Probs (S->R): ['0.41', '0.86', '0.99', '0.70']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 149/200 | Avg Steps (last 100): 146.77 | Steps: 188 | Time: 535.49s\n",
      "Reward: 188.0\n",
      "  Losses -> Gen: 57.5503 (Rew: 57.5372, Dyn: 0.0079, Reg: 0.0053)\n",
      "  Policy -> Actor: -93.0563, Critic: 9.1555\n",
      "  Causal Probs (S->R): ['0.42', '0.86', '0.99', '0.71']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 150/200 | Avg Steps (last 100): 148.45 | Steps: 183 | Time: 544.82s\n",
      "Reward: 183.0\n",
      "  Losses -> Gen: 305.6969 (Rew: 305.6878, Dyn: 0.0037, Reg: 0.0053)\n",
      "  Policy -> Actor: -96.2140, Critic: 17.9093\n",
      "  Causal Probs (S->R): ['0.42', '0.86', '0.99', '0.71']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 151/200 | Avg Steps (last 100): 150.20 | Steps: 206 | Time: 555.14s\n",
      "Reward: 206.0\n",
      "  Losses -> Gen: 146.6753 (Rew: 146.6473, Dyn: 0.0227, Reg: 0.0053)\n",
      "  Policy -> Actor: -95.6332, Critic: 8.6023\n",
      "  Causal Probs (S->R): ['0.42', '0.86', '0.99', '0.71']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 152/200 | Avg Steps (last 100): 151.64 | Steps: 206 | Time: 564.73s\n",
      "Reward: 206.0\n",
      "  Losses -> Gen: 263.0133 (Rew: 262.9884, Dyn: 0.0195, Reg: 0.0054)\n",
      "  Policy -> Actor: -93.1297, Critic: 83.4233\n",
      "  Causal Probs (S->R): ['0.43', '0.87', '0.99', '0.72']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 153/200 | Avg Steps (last 100): 153.09 | Steps: 192 | Time: 573.72s\n",
      "Reward: 192.0\n",
      "  Losses -> Gen: 38.6618 (Rew: 38.6430, Dyn: 0.0134, Reg: 0.0054)\n",
      "  Policy -> Actor: -97.3325, Critic: 7.3031\n",
      "  Causal Probs (S->R): ['0.43', '0.87', '0.99', '0.72']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 154/200 | Avg Steps (last 100): 154.79 | Steps: 193 | Time: 582.43s\n",
      "Reward: 193.0\n",
      "  Losses -> Gen: 13.4192 (Rew: 13.4097, Dyn: 0.0041, Reg: 0.0054)\n",
      "  Policy -> Actor: -97.4362, Critic: 36.0357\n",
      "  Causal Probs (S->R): ['0.44', '0.87', '0.99', '0.72']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 155/200 | Avg Steps (last 100): 155.93 | Steps: 176 | Time: 591.68s\n",
      "Reward: 176.0\n",
      "  Losses -> Gen: 474.9713 (Rew: 474.9615, Dyn: 0.0043, Reg: 0.0055)\n",
      "  Policy -> Actor: -100.9822, Critic: 131.3398\n",
      "  Causal Probs (S->R): ['0.44', '0.87', '0.99', '0.72']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 156/200 | Avg Steps (last 100): 157.75 | Steps: 195 | Time: 600.82s\n",
      "Reward: 195.0\n",
      "  Losses -> Gen: 15.7203 (Rew: 15.7095, Dyn: 0.0053, Reg: 0.0055)\n",
      "  Policy -> Actor: -98.2398, Critic: 10.4589\n",
      "  Causal Probs (S->R): ['0.45', '0.87', '0.99', '0.73']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 157/200 | Avg Steps (last 100): 159.37 | Steps: 217 | Time: 610.74s\n",
      "Reward: 217.0\n",
      "  Losses -> Gen: 57.5823 (Rew: 57.5752, Dyn: 0.0016, Reg: 0.0055)\n",
      "  Policy -> Actor: -99.6551, Critic: 6.7298\n",
      "  Causal Probs (S->R): ['0.45', '0.87', '0.99', '0.73']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 158/200 | Avg Steps (last 100): 161.42 | Steps: 232 | Time: 621.37s\n",
      "Reward: 232.0\n",
      "  Losses -> Gen: 245.8942 (Rew: 245.8830, Dyn: 0.0056, Reg: 0.0056)\n",
      "  Policy -> Actor: -102.5953, Critic: 12.0438\n",
      "  Causal Probs (S->R): ['0.46', '0.88', '0.99', '0.73']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 159/200 | Avg Steps (last 100): 162.74 | Steps: 191 | Time: 630.02s\n",
      "Reward: 191.0\n",
      "  Losses -> Gen: 39.9948 (Rew: 39.9783, Dyn: 0.0109, Reg: 0.0056)\n",
      "  Policy -> Actor: -103.5296, Critic: 7.9417\n",
      "  Causal Probs (S->R): ['0.46', '0.88', '0.99', '0.74']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 160/200 | Avg Steps (last 100): 163.93 | Steps: 184 | Time: 639.22s\n",
      "Reward: 184.0\n",
      "  Losses -> Gen: 72.5530 (Rew: 72.5453, Dyn: 0.0020, Reg: 0.0057)\n",
      "  Policy -> Actor: -106.6386, Critic: 8.9995\n",
      "  Causal Probs (S->R): ['0.47', '0.88', '0.99', '0.74']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 161/200 | Avg Steps (last 100): 165.39 | Steps: 201 | Time: 648.95s\n",
      "Reward: 201.0\n",
      "  Losses -> Gen: 21.0766 (Rew: 21.0557, Dyn: 0.0152, Reg: 0.0057)\n",
      "  Policy -> Actor: -105.2310, Critic: 10.9534\n",
      "  Causal Probs (S->R): ['0.48', '0.88', '0.99', '0.74']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 162/200 | Avg Steps (last 100): 166.57 | Steps: 207 | Time: 659.55s\n",
      "Reward: 207.0\n",
      "  Losses -> Gen: 81.6287 (Rew: 81.6151, Dyn: 0.0079, Reg: 0.0057)\n",
      "  Policy -> Actor: -106.0051, Critic: 3.5528\n",
      "  Causal Probs (S->R): ['0.48', '0.88', '0.99', '0.75']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 163/200 | Avg Steps (last 100): 167.76 | Steps: 169 | Time: 668.58s\n",
      "Reward: 169.0\n",
      "  Losses -> Gen: 719.5611 (Rew: 719.5500, Dyn: 0.0053, Reg: 0.0058)\n",
      "  Policy -> Actor: -107.1731, Critic: 14.1740\n",
      "  Causal Probs (S->R): ['0.49', '0.88', '0.99', '0.75']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 164/200 | Avg Steps (last 100): 168.75 | Steps: 177 | Time: 676.80s\n",
      "Reward: 177.0\n",
      "  Losses -> Gen: 156.6861 (Rew: 156.6721, Dyn: 0.0081, Reg: 0.0058)\n",
      "  Policy -> Actor: -106.6432, Critic: 11.3222\n",
      "  Causal Probs (S->R): ['0.49', '0.88', '0.99', '0.76']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 165/200 | Avg Steps (last 100): 169.79 | Steps: 225 | Time: 687.41s\n",
      "Reward: 225.0\n",
      "  Losses -> Gen: 262.8543 (Rew: 262.8436, Dyn: 0.0049, Reg: 0.0059)\n",
      "  Policy -> Actor: -106.1574, Critic: 53.8013\n",
      "  Causal Probs (S->R): ['0.50', '0.89', '0.99', '0.76']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 166/200 | Avg Steps (last 100): 171.17 | Steps: 217 | Time: 697.83s\n",
      "Reward: 217.0\n",
      "  Losses -> Gen: 273.2496 (Rew: 273.2402, Dyn: 0.0035, Reg: 0.0059)\n",
      "  Policy -> Actor: -110.1581, Critic: 7.9592\n",
      "  Causal Probs (S->R): ['0.51', '0.89', '0.99', '0.77']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 167/200 | Avg Steps (last 100): 172.95 | Steps: 232 | Time: 708.89s\n",
      "Reward: 232.0\n",
      "  Losses -> Gen: 32.3286 (Rew: 32.3180, Dyn: 0.0047, Reg: 0.0059)\n",
      "  Policy -> Actor: -106.8826, Critic: 9.6716\n",
      "  Causal Probs (S->R): ['0.52', '0.89', '0.99', '0.77']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 168/200 | Avg Steps (last 100): 174.50 | Steps: 227 | Time: 719.61s\n",
      "Reward: 227.0\n",
      "  Losses -> Gen: 279.7023 (Rew: 279.6910, Dyn: 0.0053, Reg: 0.0060)\n",
      "  Policy -> Actor: -111.7296, Critic: 6.0129\n",
      "  Causal Probs (S->R): ['0.52', '0.89', '0.99', '0.77']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 169/200 | Avg Steps (last 100): 174.08 | Steps: 181 | Time: 727.99s\n",
      "Reward: 181.0\n",
      "  Losses -> Gen: 97.4926 (Rew: 97.4840, Dyn: 0.0026, Reg: 0.0060)\n",
      "  Policy -> Actor: -110.6061, Critic: 31.7936\n",
      "  Causal Probs (S->R): ['0.53', '0.89', '0.99', '0.78']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 170/200 | Avg Steps (last 100): 175.39 | Steps: 210 | Time: 738.02s\n",
      "Reward: 210.0\n",
      "  Losses -> Gen: 115.3976 (Rew: 115.3897, Dyn: 0.0018, Reg: 0.0061)\n",
      "  Policy -> Actor: -113.1668, Critic: 17.8972\n",
      "  Causal Probs (S->R): ['0.53', '0.89', '0.99', '0.78']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 171/200 | Avg Steps (last 100): 176.89 | Steps: 238 | Time: 749.41s\n",
      "Reward: 238.0\n",
      "  Losses -> Gen: 179.5250 (Rew: 179.5108, Dyn: 0.0081, Reg: 0.0061)\n",
      "  Policy -> Actor: -114.2209, Critic: 7.3847\n",
      "  Causal Probs (S->R): ['0.54', '0.90', '0.99', '0.78']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 172/200 | Avg Steps (last 100): 177.95 | Steps: 214 | Time: 759.35s\n",
      "Reward: 214.0\n",
      "  Losses -> Gen: 130.4513 (Rew: 130.4379, Dyn: 0.0073, Reg: 0.0061)\n",
      "  Policy -> Actor: -115.9640, Critic: 13.8260\n",
      "  Causal Probs (S->R): ['0.55', '0.90', '0.99', '0.79']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 173/200 | Avg Steps (last 100): 179.40 | Steps: 232 | Time: 770.77s\n",
      "Reward: 232.0\n",
      "  Losses -> Gen: 48.7080 (Rew: 48.6976, Dyn: 0.0042, Reg: 0.0062)\n",
      "  Policy -> Actor: -114.9561, Critic: 9.9761\n",
      "  Causal Probs (S->R): ['0.55', '0.90', '0.99', '0.79']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 174/200 | Avg Steps (last 100): 180.74 | Steps: 225 | Time: 777.37s\n",
      "Reward: 225.0\n",
      "  Losses -> Gen: 137.4197 (Rew: 137.4113, Dyn: 0.0022, Reg: 0.0062)\n",
      "  Policy -> Actor: -116.4508, Critic: 10.6790\n",
      "  Causal Probs (S->R): ['0.56', '0.90', '0.99', '0.79']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 175/200 | Avg Steps (last 100): 182.19 | Steps: 221 | Time: 784.33s\n",
      "Reward: 221.0\n",
      "  Losses -> Gen: 21.4513 (Rew: 21.4370, Dyn: 0.0081, Reg: 0.0063)\n",
      "  Policy -> Actor: -121.9267, Critic: 2.8751\n",
      "  Causal Probs (S->R): ['0.57', '0.90', '0.99', '0.80']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 176/200 | Avg Steps (last 100): 183.37 | Steps: 177 | Time: 792.73s\n",
      "Reward: 177.0\n",
      "  Losses -> Gen: 29.0398 (Rew: 29.0315, Dyn: 0.0020, Reg: 0.0063)\n",
      "  Policy -> Actor: -118.2698, Critic: 18.5615\n",
      "  Causal Probs (S->R): ['0.57', '0.91', '0.99', '0.80']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 177/200 | Avg Steps (last 100): 184.90 | Steps: 222 | Time: 803.72s\n",
      "Reward: 222.0\n",
      "  Losses -> Gen: 48.2892 (Rew: 48.2798, Dyn: 0.0031, Reg: 0.0064)\n",
      "  Policy -> Actor: -121.5865, Critic: 14.9538\n",
      "  Causal Probs (S->R): ['0.58', '0.91', '0.99', '0.81']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 178/200 | Avg Steps (last 100): 185.99 | Steps: 196 | Time: 812.98s\n",
      "Reward: 196.0\n",
      "  Losses -> Gen: 45.6818 (Rew: 45.6724, Dyn: 0.0030, Reg: 0.0064)\n",
      "  Policy -> Actor: -125.1846, Critic: 66.9936\n",
      "  Causal Probs (S->R): ['0.58', '0.91', '0.99', '0.81']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 179/200 | Avg Steps (last 100): 187.05 | Steps: 179 | Time: 821.43s\n",
      "Reward: 179.0\n",
      "  Losses -> Gen: 123.9089 (Rew: 123.9009, Dyn: 0.0016, Reg: 0.0064)\n",
      "  Policy -> Actor: -120.5991, Critic: 75.2455\n",
      "  Causal Probs (S->R): ['0.59', '0.91', '0.99', '0.81']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 180/200 | Avg Steps (last 100): 187.44 | Steps: 218 | Time: 828.63s\n",
      "Reward: 218.0\n",
      "  Losses -> Gen: 27.5051 (Rew: 27.4955, Dyn: 0.0031, Reg: 0.0065)\n",
      "  Policy -> Actor: -121.6063, Critic: 13.0454\n",
      "  Causal Probs (S->R): ['0.60', '0.91', '0.99', '0.81']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 181/200 | Avg Steps (last 100): 188.80 | Steps: 206 | Time: 835.05s\n",
      "Reward: 206.0\n",
      "  Losses -> Gen: 72.1169 (Rew: 72.1067, Dyn: 0.0037, Reg: 0.0065)\n",
      "  Policy -> Actor: -120.9471, Critic: 5.5642\n",
      "  Causal Probs (S->R): ['0.61', '0.91', '0.99', '0.82']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 182/200 | Avg Steps (last 100): 189.82 | Steps: 231 | Time: 841.78s\n",
      "Reward: 231.0\n",
      "  Losses -> Gen: 41.2479 (Rew: 41.2310, Dyn: 0.0103, Reg: 0.0066)\n",
      "  Policy -> Actor: -127.7435, Critic: 3.4082\n",
      "  Causal Probs (S->R): ['0.61', '0.92', '0.99', '0.82']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 183/200 | Avg Steps (last 100): 191.11 | Steps: 212 | Time: 850.40s\n",
      "Reward: 212.0\n",
      "  Losses -> Gen: 114.5599 (Rew: 114.5516, Dyn: 0.0017, Reg: 0.0066)\n",
      "  Policy -> Actor: -122.6401, Critic: 22.0586\n",
      "  Causal Probs (S->R): ['0.62', '0.92', '0.99', '0.82']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 184/200 | Avg Steps (last 100): 191.98 | Steps: 179 | Time: 858.14s\n",
      "Reward: 179.0\n",
      "  Losses -> Gen: 17.3574 (Rew: 17.3474, Dyn: 0.0034, Reg: 0.0066)\n",
      "  Policy -> Actor: -129.7162, Critic: 9.1157\n",
      "  Causal Probs (S->R): ['0.62', '0.92', '0.99', '0.83']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 185/200 | Avg Steps (last 100): 193.00 | Steps: 185 | Time: 866.92s\n",
      "Reward: 185.0\n",
      "  Losses -> Gen: 137.5844 (Rew: 137.5737, Dyn: 0.0040, Reg: 0.0067)\n",
      "  Policy -> Actor: -127.4218, Critic: 90.4572\n",
      "  Causal Probs (S->R): ['0.63', '0.92', '0.99', '0.83']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 186/200 | Avg Steps (last 100): 194.03 | Steps: 193 | Time: 876.33s\n",
      "Reward: 193.0\n",
      "  Losses -> Gen: 16.1035 (Rew: 16.0940, Dyn: 0.0028, Reg: 0.0067)\n",
      "  Policy -> Actor: -122.5012, Critic: 29.6561\n",
      "  Causal Probs (S->R): ['0.64', '0.92', '0.99', '0.83']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 187/200 | Avg Steps (last 100): 194.92 | Steps: 180 | Time: 885.16s\n",
      "Reward: 180.0\n",
      "  Losses -> Gen: 30.7399 (Rew: 30.7310, Dyn: 0.0022, Reg: 0.0068)\n",
      "  Policy -> Actor: -128.5034, Critic: 6.0790\n",
      "  Causal Probs (S->R): ['0.64', '0.92', '0.99', '0.84']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 188/200 | Avg Steps (last 100): 195.50 | Steps: 203 | Time: 894.89s\n",
      "Reward: 203.0\n",
      "  Losses -> Gen: 14.2482 (Rew: 14.2384, Dyn: 0.0030, Reg: 0.0068)\n",
      "  Policy -> Actor: -131.4307, Critic: 7.6504\n",
      "  Causal Probs (S->R): ['0.65', '0.92', '0.99', '0.84']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 189/200 | Avg Steps (last 100): 196.76 | Steps: 262 | Time: 907.18s\n",
      "Reward: 262.0\n",
      "  Losses -> Gen: 133.8945 (Rew: 133.8849, Dyn: 0.0028, Reg: 0.0068)\n",
      "  Policy -> Actor: -129.7615, Critic: 42.3850\n",
      "  Causal Probs (S->R): ['0.65', '0.92', '0.99', '0.84']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 190/200 | Avg Steps (last 100): 197.54 | Steps: 184 | Time: 915.77s\n",
      "Reward: 184.0\n",
      "  Losses -> Gen: 223.5320 (Rew: 223.5192, Dyn: 0.0059, Reg: 0.0069)\n",
      "  Policy -> Actor: -128.4734, Critic: 18.1443\n",
      "  Causal Probs (S->R): ['0.66', '0.93', '0.99', '0.84']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 191/200 | Avg Steps (last 100): 198.70 | Steps: 223 | Time: 927.16s\n",
      "Reward: 223.0\n",
      "  Losses -> Gen: 382.0581 (Rew: 382.0472, Dyn: 0.0039, Reg: 0.0069)\n",
      "  Policy -> Actor: -132.4316, Critic: 63.4723\n",
      "  Causal Probs (S->R): ['0.67', '0.93', '1.00', '0.85']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 192/200 | Avg Steps (last 100): 199.07 | Steps: 172 | Time: 936.11s\n",
      "Reward: 172.0\n",
      "  Losses -> Gen: 16.4814 (Rew: 16.4688, Dyn: 0.0056, Reg: 0.0070)\n",
      "  Policy -> Actor: -131.0416, Critic: 5.1579\n",
      "  Causal Probs (S->R): ['0.67', '0.93', '1.00', '0.85']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 193/200 | Avg Steps (last 100): 199.69 | Steps: 186 | Time: 945.00s\n",
      "Reward: 186.0\n",
      "  Losses -> Gen: 32.3203 (Rew: 32.3111, Dyn: 0.0023, Reg: 0.0070)\n",
      "  Policy -> Actor: -131.8196, Critic: 65.5847\n",
      "  Causal Probs (S->R): ['0.68', '0.93', '1.00', '0.85']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 194/200 | Avg Steps (last 100): 200.34 | Steps: 202 | Time: 953.16s\n",
      "Reward: 202.0\n",
      "  Losses -> Gen: 306.6807 (Rew: 306.6599, Dyn: 0.0137, Reg: 0.0070)\n",
      "  Policy -> Actor: -135.7179, Critic: 9.9623\n",
      "  Causal Probs (S->R): ['0.68', '0.93', '1.00', '0.85']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 195/200 | Avg Steps (last 100): 200.91 | Steps: 197 | Time: 962.58s\n",
      "Reward: 197.0\n",
      "  Losses -> Gen: 23.4971 (Rew: 23.4884, Dyn: 0.0016, Reg: 0.0071)\n",
      "  Policy -> Actor: -130.9277, Critic: 21.0217\n",
      "  Causal Probs (S->R): ['0.69', '0.93', '1.00', '0.86']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 196/200 | Avg Steps (last 100): 201.98 | Steps: 227 | Time: 973.35s\n",
      "Reward: 227.0\n",
      "  Losses -> Gen: 7.9345 (Rew: 7.9247, Dyn: 0.0026, Reg: 0.0071)\n",
      "  Policy -> Actor: -135.2979, Critic: 5.2328\n",
      "  Causal Probs (S->R): ['0.69', '0.93', '1.00', '0.86']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 197/200 | Avg Steps (last 100): 202.59 | Steps: 185 | Time: 982.03s\n",
      "Reward: 185.0\n",
      "  Losses -> Gen: 24.4010 (Rew: 24.3918, Dyn: 0.0020, Reg: 0.0072)\n",
      "  Policy -> Actor: -131.6958, Critic: 6.0016\n",
      "  Causal Probs (S->R): ['0.70', '0.93', '1.00', '0.86']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 198/200 | Avg Steps (last 100): 202.49 | Steps: 181 | Time: 990.58s\n",
      "Reward: 181.0\n",
      "  Losses -> Gen: 40.6891 (Rew: 40.6737, Dyn: 0.0081, Reg: 0.0072)\n",
      "  Policy -> Actor: -133.6313, Critic: 9.5371\n",
      "  Causal Probs (S->R): ['0.70', '0.93', '1.00', '0.86']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 199/200 | Avg Steps (last 100): 203.20 | Steps: 179 | Time: 999.36s\n",
      "Reward: 179.0\n",
      "  Losses -> Gen: 8.1455 (Rew: 8.1368, Dyn: 0.0015, Reg: 0.0072)\n",
      "  Policy -> Actor: -138.7756, Critic: 9.5749\n",
      "  Causal Probs (S->R): ['0.71', '0.94', '1.00', '0.87']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n",
      "Epi 200/200 | Avg Steps (last 100): 203.55 | Steps: 195 | Time: 1008.38s\n",
      "Reward: 195.0\n",
      "  Losses -> Gen: 19.7120 (Rew: 19.7037, Dyn: 0.0010, Reg: 0.0073)\n",
      "  Policy -> Actor: -133.8634, Critic: 9.9626\n",
      "  Causal Probs (S->R): ['0.71', '0.94', '1.00', '0.87']\n",
      "  Compact Mask: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from modules import RewardModel, GenerativeModel, ReplayBuffer, DiscreteSACAgent, EpisodicRewardWrapper\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LR_POLICY = 3e-4          # Learning rate for actor and critic\n",
    "LR_GENERATIVE = 3e-4      # Learning rate for generative model\n",
    "GAMMA = 0.99              # Discount factor\n",
    "REPLAY_BUFFER_SIZE = 50000 # Size of the replay buffer\n",
    "BATCH_SIZE = 256          # Batch size for training\n",
    "TAU = 0.005               # Soft update coefficient for target networks\n",
    "ALPHA = 0.2               # SAC temperature parameter (entropy regularization)\n",
    "HIDDEN_DIM = 256          # Hidden dimension for neural networks\n",
    "MAX_EPISODES = 200       # Total number of episodes to run\n",
    "MAX_STEPS_PER_EPISODE = 500 # Max steps per episode for CartPole-v1\n",
    "START_TRAINING_EPISODES = 10 # Number of episodes to collect data before training starts\n",
    "\n",
    "# Hyperparameters for the GRD generative model loss (L_reg)\n",
    "# These control the sparsity of the learned causal graph. Increased to encourage sparsity.\n",
    "LAMBDA_S_R = 5e-4  # state -> reward\n",
    "LAMBDA_A_R = 1e-5  # action -> reward\n",
    "LAMBDA_S_S = 5e-5  # state -> state\n",
    "LAMBDA_A_S = 1e-8  # action -> state\n",
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "env = EpisodicRewardWrapper(env)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "compact_state_dim = state_dim \n",
    "\n",
    "replay_buffer = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "generative_model = GenerativeModel(state_dim, action_dim, HIDDEN_DIM, DEVICE, LR_GENERATIVE, GAMMA, LAMBDA_S_S, LAMBDA_S_R, LAMBDA_A_S, LAMBDA_A_R)\n",
    "sac_agent = DiscreteSACAgent(state_dim, action_dim, compact_state_dim, HIDDEN_DIM, DEVICE, LR_POLICY, TAU, GAMMA, ALPHA)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"State dim: {state_dim}, Action dim: {action_dim}\")\n",
    "\n",
    "start_time = time.time()\n",
    "all_episode_steps = []\n",
    "\n",
    "rewards = []\n",
    "\n",
    "for i_episode in range(1, MAX_EPISODES + 1):\n",
    "    state, _ = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    episode_states = []\n",
    "    episode_actions = []\n",
    "    \n",
    "    for t in range(MAX_STEPS_PER_EPISODE):\n",
    "        with torch.no_grad():\n",
    "            C_s_s, _, C_s_r, _ = generative_model.causal_module.get_causal_masks(training=False)\n",
    "            compact_mask = generative_model.causal_module.get_compact_representation_mask(C_s_s, C_s_r)\n",
    "            compact_state = state * compact_mask\n",
    "\n",
    "        action = sac_agent.select_action(compact_state)\n",
    "        \n",
    "        next_state_np, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # The episodic reward is only non-zero at the end\n",
    "        # The immediate reward for the replay buffer is this episodic reward if done, else 0\n",
    "        replay_reward = reward if done else 0.0\n",
    "        episode_reward += reward \n",
    "        \n",
    "        next_state = torch.tensor(next_state_np, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "        \n",
    "        # Push the transition with the immediate (mostly zero) reward\n",
    "        replay_buffer.push(state, action, next_state, replay_reward, done)\n",
    "        episode_states.append(state)\n",
    "        episode_actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "        if len(replay_buffer) > BATCH_SIZE and i_episode > START_TRAINING_EPISODES:\n",
    "            # Update Generative Model\n",
    "            generative_model.optimizer.zero_grad()\n",
    "            transitions = replay_buffer.sample(BATCH_SIZE)\n",
    "            trajectories = replay_buffer.sample_trajectories(4)\n",
    "            gen_loss, l_rew, l_dyn, l_reg = generative_model.calculate_loss(trajectories, transitions)\n",
    "            if torch.is_tensor(gen_loss):\n",
    "                gen_loss.backward()\n",
    "                generative_model.optimizer.step()\n",
    "\n",
    "            # Update Policy Model\n",
    "            actor_loss, critic_loss = sac_agent.update(transitions, generative_model)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    all_episode_steps.append(t + 1)\n",
    "\n",
    "    # After episode ends, store the full trajectory with the final episodic return\n",
    "    if episode_reward > 0:\n",
    "        ep_states_tensor = torch.cat(episode_states, dim=0)\n",
    "        ep_actions_tensor = torch.tensor(episode_actions, device=DEVICE, dtype=torch.long)\n",
    "        ep_return_tensor = torch.tensor([episode_reward], dtype=torch.float32, device=DEVICE)\n",
    "        replay_buffer.push_trajectory(ep_states_tensor, ep_actions_tensor, ep_return_tensor)\n",
    "\n",
    "    if i_episode % 1 == 0:\n",
    "        avg_steps = np.mean(all_episode_steps[-100:]) # Average over last 100 episodes\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Epi {i_episode}/{MAX_EPISODES} | Avg Steps (last 100): {avg_steps:.2f} | Steps: {t+1} | Time: {elapsed_time:.2f}s\")\n",
    "        print(f\"Reward: {episode_reward}\")\n",
    "        rewards.append(episode_reward)\n",
    "        if len(replay_buffer) > BATCH_SIZE and i_episode > START_TRAINING_EPISODES and torch.is_tensor(gen_loss):\n",
    "            print(f\"  Losses -> Gen: {gen_loss.item():.4f} (Rew: {l_rew.item():.4f}, Dyn: {l_dyn.item():.4f}, Reg: {l_reg.item():.4f})\")\n",
    "            print(f\"  Policy -> Actor: {actor_loss:.4f}, Critic: {critic_loss:.4f}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            C_s_s, _, C_s_r, C_a_r = generative_model.causal_module.get_causal_masks(training=False)\n",
    "            compact_mask = generative_model.causal_module.get_compact_representation_mask(C_s_s, C_s_r)\n",
    "            s_r_probs = F.softmax(generative_model.causal_module.s_to_r_logits, dim=-1)[:, 1].cpu().numpy()\n",
    "            a_r_probs = F.softmax(generative_model.causal_module.a_to_r_logits, dim=-1)[:, 1].cpu().numpy()\n",
    "            print(f\"  Causal Probs (S->R): {[f'{p:.2f}' for p in s_r_probs]}\")\n",
    "            print(f\"  Compact Mask: {compact_mask.cpu().numpy()}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60086a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.0,\n",
       " 18.0,\n",
       " 10.0,\n",
       " 16.0,\n",
       " 52.0,\n",
       " 9.0,\n",
       " 20.0,\n",
       " 17.0,\n",
       " 13.0,\n",
       " 15.0,\n",
       " 11.0,\n",
       " 15.0,\n",
       " 39.0,\n",
       " 14.0,\n",
       " 17.0,\n",
       " 13.0,\n",
       " 15.0,\n",
       " 9.0,\n",
       " 30.0,\n",
       " 17.0,\n",
       " 11.0,\n",
       " 21.0,\n",
       " 33.0,\n",
       " 12.0,\n",
       " 15.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 15.0,\n",
       " 28.0,\n",
       " 27.0,\n",
       " 16.0,\n",
       " 27.0,\n",
       " 37.0,\n",
       " 46.0,\n",
       " 18.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 39.0,\n",
       " 17.0,\n",
       " 53.0,\n",
       " 9.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 12.0,\n",
       " 15.0,\n",
       " 23.0,\n",
       " 29.0,\n",
       " 32.0,\n",
       " 15.0,\n",
       " 31.0,\n",
       " 62.0,\n",
       " 47.0,\n",
       " 23.0,\n",
       " 62.0,\n",
       " 13.0,\n",
       " 55.0,\n",
       " 27.0,\n",
       " 59.0,\n",
       " 65.0,\n",
       " 55.0,\n",
       " 89.0,\n",
       " 50.0,\n",
       " 78.0,\n",
       " 121.0,\n",
       " 79.0,\n",
       " 54.0,\n",
       " 72.0,\n",
       " 223.0,\n",
       " 79.0,\n",
       " 88.0,\n",
       " 108.0,\n",
       " 87.0,\n",
       " 91.0,\n",
       " 76.0,\n",
       " 59.0,\n",
       " 69.0,\n",
       " 87.0,\n",
       " 73.0,\n",
       " 179.0,\n",
       " 70.0,\n",
       " 129.0,\n",
       " 83.0,\n",
       " 92.0,\n",
       " 83.0,\n",
       " 90.0,\n",
       " 91.0,\n",
       " 145.0,\n",
       " 136.0,\n",
       " 106.0,\n",
       " 107.0,\n",
       " 135.0,\n",
       " 124.0,\n",
       " 137.0,\n",
       " 140.0,\n",
       " 120.0,\n",
       " 124.0,\n",
       " 191.0,\n",
       " 108.0,\n",
       " 160.0,\n",
       " 173.0,\n",
       " 155.0,\n",
       " 172.0,\n",
       " 145.0,\n",
       " 224.0,\n",
       " 177.0,\n",
       " 112.0,\n",
       " 179.0,\n",
       " 205.0,\n",
       " 268.0,\n",
       " 187.0,\n",
       " 217.0,\n",
       " 222.0,\n",
       " 223.0,\n",
       " 222.0,\n",
       " 201.0,\n",
       " 268.0,\n",
       " 288.0,\n",
       " 215.0,\n",
       " 273.0,\n",
       " 213.0,\n",
       " 197.0,\n",
       " 187.0,\n",
       " 206.0,\n",
       " 232.0,\n",
       " 195.0,\n",
       " 227.0,\n",
       " 251.0,\n",
       " 215.0,\n",
       " 207.0,\n",
       " 225.0,\n",
       " 212.0,\n",
       " 207.0,\n",
       " 213.0,\n",
       " 176.0,\n",
       " 185.0,\n",
       " 190.0,\n",
       " 229.0,\n",
       " 188.0,\n",
       " 197.0,\n",
       " 182.0,\n",
       " 206.0,\n",
       " 191.0,\n",
       " 191.0,\n",
       " 173.0,\n",
       " 196.0,\n",
       " 200.0,\n",
       " 225.0,\n",
       " 188.0,\n",
       " 183.0,\n",
       " 206.0,\n",
       " 206.0,\n",
       " 192.0,\n",
       " 193.0,\n",
       " 176.0,\n",
       " 195.0,\n",
       " 217.0,\n",
       " 232.0,\n",
       " 191.0,\n",
       " 184.0,\n",
       " 201.0,\n",
       " 207.0,\n",
       " 169.0,\n",
       " 177.0,\n",
       " 225.0,\n",
       " 217.0,\n",
       " 232.0,\n",
       " 227.0,\n",
       " 181.0,\n",
       " 210.0,\n",
       " 238.0,\n",
       " 214.0,\n",
       " 232.0,\n",
       " 225.0,\n",
       " 221.0,\n",
       " 177.0,\n",
       " 222.0,\n",
       " 196.0,\n",
       " 179.0,\n",
       " 218.0,\n",
       " 206.0,\n",
       " 231.0,\n",
       " 212.0,\n",
       " 179.0,\n",
       " 185.0,\n",
       " 193.0,\n",
       " 180.0,\n",
       " 203.0,\n",
       " 262.0,\n",
       " 184.0,\n",
       " 223.0,\n",
       " 172.0,\n",
       " 186.0,\n",
       " 202.0,\n",
       " 197.0,\n",
       " 227.0,\n",
       " 185.0,\n",
       " 181.0,\n",
       " 179.0,\n",
       " 195.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04dc3996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "nrewards = np.array(rewards, dtype=float)\n",
    "nrewards = np.cumsum(nrewards)\n",
    "plt.plot(range(len(nrewards)), nrewards)\n",
    "plt.show()\n",
    "\n",
    "with open('weights/rewards.pkl', 'wb') as f:\n",
    "    pkl.dump(rewards, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8b0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_agent.save('weights')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
